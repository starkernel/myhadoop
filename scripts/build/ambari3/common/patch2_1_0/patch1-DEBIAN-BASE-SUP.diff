Subject: [PATCH] feature: 支持ubuntu22的基础调整
---
Index: ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/metainfo.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/metainfo.xml b/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/metainfo.xml
--- a/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/metainfo.xml	(revision 435e421d3b4b891181eadaae96d9bc64716c5603)
+++ b/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/metainfo.xml	(date 1753144685708)
@@ -309,13 +309,13 @@
               <name>hadoop-${stack_version}-client</name>
             </package>
             <package>
-              <name>snappy</name>
+              <name>libsnappy1v5</name>
             </package>
             <package>
               <name>libsnappy-dev</name>
             </package>
             <package>
-              <name>hadoop-${stack_version}-libhdfs</name>
+              <name>hadoop-${stack_version}-libhdfs0</name>
             </package>
             <package>
               <name>libtirpc-dev</name>
Index: ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/package/scripts/hdfs.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/package/scripts/hdfs.py b/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/package/scripts/hdfs.py
--- a/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/package/scripts/hdfs.py	(revision 435e421d3b4b891181eadaae96d9bc64716c5603)
+++ b/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/HDFS/package/scripts/hdfs.py	(date 1753070815035)
@@ -49,6 +49,12 @@
               group='root'
               )

+    Directory(params.hadoop_conf_dir,
+              create_parents=True,
+              owner='root',
+              group='root'
+              )
+
     File(os.path.join(params.limits_conf_dir, 'hdfs.conf'),
          owner='root',
          group='root',
Index: ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/metainfo.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/metainfo.xml b/ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/metainfo.xml
--- a/ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/metainfo.xml	(revision 435e421d3b4b891181eadaae96d9bc64716c5603)
+++ b/ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/metainfo.xml	(date 1753693447790)
@@ -192,7 +192,7 @@
           </packages>
         </osSpecific>
         <osSpecific>
-          <osFamily>ubuntu16</osFamily>
+          <osFamily>ubuntu22</osFamily>
           <packages>
             <package>
               <name>ambari-metrics-assembly</name>
Index: ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/ZEPPELIN/package/scripts/zeppelin_server.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/ZEPPELIN/package/scripts/zeppelin_server.py b/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/ZEPPELIN/package/scripts/zeppelin_server.py
--- a/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/ZEPPELIN/package/scripts/zeppelin_server.py	(revision 435e421d3b4b891181eadaae96d9bc64716c5603)
+++ b/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/ZEPPELIN/package/scripts/zeppelin_server.py	(date 1753513531699)
@@ -285,7 +285,7 @@
     interpreter_settings = config_data['interpreterSettings']

     if upgrade_type is not None:
-      current_interpreters_keys = interpreter_settings.keys()
+      current_interpreters_keys = list(interpreter_settings.keys())
       for key in current_interpreters_keys:
         interpreter_data = interpreter_settings[key]
         if interpreter_data["name"] == "sh" and interpreter_data["group"] == "sh":
@@ -529,7 +529,7 @@
         del interpreter_settings[key]

     hive_interactive_properties_key = 'hive_interactive'
-    for setting_key in interpreter_settings.keys():
+    for setting_key in list(interpreter_settings.keys()):
       interpreter = interpreter_settings[setting_key]
       if interpreter['group'] == 'jdbc' and interpreter['name'] == 'jdbc' and ('jdbc' not in exclude_interpreter_autoconfig_list
                                                                or 'jdbc' in exclude_interpreter_property_groups_map.keys()):
Index: ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/SPARK/metainfo.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/SPARK/metainfo.xml b/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/SPARK/metainfo.xml
--- a/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/SPARK/metainfo.xml	(revision 435e421d3b4b891181eadaae96d9bc64716c5603)
+++ b/ambari-server/src/main/resources/stacks/BIGTOP/3.2.0/services/SPARK/metainfo.xml	(date 1753513531738)
@@ -227,7 +227,7 @@
           <osFamily>ubuntu22</osFamily>
           <packages>
             <package>
-              <name>spark-${stack_version}-core</name>
+              <name>spark-${stack_version}</name>
             </package>
             <package>
               <name>spark-${stack_version}-python</name>
Index: ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/package/scripts/split_points.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/package/scripts/split_points.py b/ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/package/scripts/split_points.py
--- a/ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/package/scripts/split_points.py	(revision 435e421d3b4b891181eadaae96d9bc64716c5603)
+++ b/ambari-server/src/main/resources/common-services/AMBARI_METRICS/3.0.0/package/scripts/split_points.py	(date 1753756249988)
@@ -66,17 +66,15 @@
   return to_number(strvalue) * m


-# Class that takes AMS HBase configs as input and determines the Region
-# pre-splits based on selected services also passed as a parameter to the class.
 class FindSplitPointsForAMSRegions:
   def __init__(
-    self,
-    ams_hbase_site,
-    ams_hbase_env,
-    serviceMetricsDir,
-    customServiceMetricsDir,
-    operation_mode="embedded",
-    services=None,
+          self,
+          ams_hbase_site,
+          ams_hbase_env,
+          serviceMetricsDir,
+          customServiceMetricsDir,
+          operation_mode="embedded",
+          services=None,
   ):
     self.ams_hbase_site = ams_hbase_site
     self.ams_hbase_env = ams_hbase_env
@@ -84,15 +82,12 @@
     self.customServiceMetricsDir = customServiceMetricsDir
     self.services = services
     self.mode = operation_mode
-    # Add host metrics if not present as input
     if self.services and "HOST" not in self.services:
       self.services.append("HOST")

-    # Initialize before user
     self.initialize()

   def initialize(self):
-    # calculate regions based on available memory
     self.initialize_region_counts()
     self.initialize_ordered_set_of_metrics()

@@ -111,41 +106,39 @@
         xmx_bytes = xmx_region_bytes

       memstore_max_mem = (
-        float(self.ams_hbase_site["hbase.regionserver.global.memstore.upperLimit"])
-        * xmx_bytes
+              float(self.ams_hbase_site["hbase.regionserver.global.memstore.upperLimit"])
+              * xmx_bytes
       )
       memstore_flush_size = format_Xmx_size_to_bytes(
         self.ams_hbase_site["hbase.hregion.memstore.flush.size"]
       )

       max_inmemory_regions = (
-        memstore_max_mem / memstore_flush_size
-      ) - other_region_static_count
+                                     memstore_max_mem / memstore_flush_size
+                             ) - other_region_static_count
       print(f"max_inmemory_regions: {max_inmemory_regions}")

+      # 强制 int 类型，防止 float 下标
+      max_inmemory_regions = int(max_inmemory_regions)
+
       if max_inmemory_regions > 2:
-        # Lets say total = 25, so we have 20 regions to allocate between
-        # METRIC_RECORD, METRIC_AGGREGATE & METRIC_RECORD_MINUTE tables, desired = (14, 3, 3)
-        # 70 % to METRIC_RECORD
         self.desired_precision_region_count = max(
           2, int(math.floor(0.70 * max_inmemory_regions))
         )
-        # 15% each to METRIC_AGGREGATE & METRIC_RECORD_MINUTE
         self.desired_aggregate_region_count = max(
           2, int(math.floor(0.15 * max_inmemory_regions))
         )
       else:
         self.desired_precision_region_count = 2
         self.desired_aggregate_region_count = 2
-    except:
-      print("Bad config settings, could not calculate max regions available.")
+    except Exception as ex:
+      print("Bad config settings, could not calculate max regions available.", ex)
     pass

   def initialize_ordered_set_of_metrics(self):
     metrics = set()
     self.gatherMetrics(metrics, self.serviceMetricsDir)
     self.gatherMetrics(metrics, self.customServiceMetricsDir)
-
     self.metrics = sorted(metrics)
     print(f"metrics length: {len(self.metrics)}")

@@ -156,34 +149,34 @@
       return

     for file in files:
-      # Process for stack services selected at deploy time or all stack services if
-      # services arg is not passed
       if self.services is None or file.rstrip(metric_filename_ext) in self.services:
         print(f"Processing file: {os.path.join(dir, file)}")
         service_metrics = set()
         with open(os.path.join(dir, file), "r") as f:
           for metric in f:
             service_metrics.add(metric.strip())
-          pass
-        pass
         metrics.update(self.find_equidistant_metrics(list(sorted(service_metrics))))
-      pass
-    pass

-  # Pick 50 metric points for each service that are equidistant from
-  # each other for a service
   def find_equidistant_metrics(self, service_metrics):
     equi_metrics = []
-    idx = len(service_metrics) / max_equidistant_points
-    if idx == 0:
+    total = len(service_metrics)
+    if total == 0:
+      return equi_metrics
+    if total <= max_equidistant_points:
       return service_metrics
-    pass

+    # 保证 idx 是 float，但后面下标用 int 包裹
+    idx = total / max_equidistant_points
     index = idx
     for i in range(0, max_equidistant_points - 1):
-      equi_metrics.append(service_metrics[index - 1])
+      int_index = int(round(index - 1))
+      # 防止越界
+      if int_index < 0:
+        int_index = 0
+      if int_index >= total:
+        break
+      equi_metrics.append(service_metrics[int_index])
       index += idx
-    pass

     return equi_metrics

@@ -213,8 +206,6 @@

     return split_points

-  pass
-

 def main(argv=None):
   scriptDir = os.path.realpath(os.path.dirname(argv[0]))
@@ -227,7 +218,6 @@
         "Usage: dict(ams-hbase-site) dict(ams-hbase-env) list(services)\n"
       )
       sys.exit(2)
-    pass

     ams_hbase_site = None
     ams_hbase_env = None
@@ -238,7 +228,6 @@
       services = onlyargs[2]
       if services:
         services = str(services).split(",")
-      pass
     except Exception as ex:
       sys.stderr.write(str(ex))
       sys.stderr.write(
